app:
  description: 'æ ¹æ®ä»£ç æ¨¡æ¿å’Œ OpenAPI å®šä¹‰è‡ªåŠ¨ä»¿å†™ç”Ÿæˆæ–°ä»£ç '
  icon: ğŸ¤–
  icon_background: '#FFEAD5'
  mode: advanced-chat
  name: AI-Code-Mimic-Advanced
  use_icon_as_answer_icon: false
kind: app
version: 0.1.5
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
  graph:
    edges:
      - data:
          sourceType: start
          targetType: llm
        id: start-to-llm
        source: 'start-node'
        sourceHandle: source
        target: 'llm-node'
        targetHandle: target
        type: custom
      - data:
          sourceType: llm
          targetType: answer
        id: llm-to-answer
        source: 'llm-node'
        sourceHandle: source
        target: 'answer-node'
        targetHandle: target
        type: custom
    nodes:
      - data:
          desc: 'æ¥æ”¶å‰ç«¯ä¼ æ¥çš„æ¨¡æ¿å’Œ API å®šä¹‰'
          title: å¼€å§‹
          type: start
          variables:
            - label: ä»£ç æ¨¡æ¿
              required: true
              type: paragraph
              variable: code_template
            - label: APIå®šä¹‰
              required: true
              type: paragraph
              variable: api_definitions
            - label: å…¨å±€æ¥å£å®šä¹‰
              required: false
              type: paragraph
              variable: global_interfaces
        height: 89
        id: 'start-node'
        position:
          x: 80
          y: 282
        positionAbsolute:
          x: 80
          y: 282
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: 'æ ¸å¿ƒä»£ç ä»¿å†™é€»è¾‘'
          model:
            mode: chat
            name: qwen3-vl-235b-a22b-thinking
            provider: langgenius/tongyi/tongyi
            completion_params:
              temperature: 0.2
          prompt_template:
            - id: system-prompt
              role: system
              text: |
                # Dify LLM System Prompt - AI Code Mimic

                ## ğŸ¯ ä»»åŠ¡è§’è‰²

                You are an expert TypeScript/React code generator. Your task is to analyze existing code patterns and generate new code for different API endpoints while maintaining EXACT consistency in style, structure, and conventions.

                ## ğŸ“– å…¨å±€ç±»å‹å®šä¹‰ (Reference Only)

                ç”Ÿæˆçš„ä»£ç å¿…é¡»ä¼˜å…ˆä½¿ç”¨ä»¥ä¸‹é¡¹ç›®ä¸­å®šä¹‰çš„é€šç”¨æ³›å‹åŒ…è£…å™¨ï¼š

                ```typescript
                {{#start-node.global_interfaces#}}
                ```

                ## ğŸ“¥ è¾“å…¥å˜é‡

                ### 1. Code Template (ä»£ç æ¨¡æ¿)
                ```
                {{#start-node.code_template#}}
                ```

                ### 2. API Definitions (ç›®æ ‡æ¥å£å®šä¹‰)
                ```
                {{#start-node.api_definitions#}}
                ```

                ## ğŸ“‹ æ‰§è¡Œæ­¥éª¤

                ### Step 1: æ·±åº¦åˆ†ææ¨¡æ¿
                - **ç»“æ„æ£€æŸ¥**: æ¨¡æ¿æ˜¯å¯¼å‡ºç‹¬ç«‹æ¥å£è¿˜æ˜¯ç»Ÿä¸€çš„ `Api` å¯¹è±¡ï¼Ÿå¦‚æœæ˜¯å¯¹è±¡ï¼Œå¿…é¡»å°†æ–°æ–¹æ³•è¿½åŠ åˆ°å¯¹è±¡ä¸­ã€‚
                - **ä¾èµ–åº“è°ƒç”¨**: ä¸¥æ ¼æ¨¡ä»¿ `request.get({ url, params })` æˆ– `request.post({ url, data })`ã€‚
                - **æ³›å‹é€‰æ‹©**:
                  - å¦‚æœ API å“åº”åŒ…å« `list` å’Œ `total` -> **å¿…é¡»**ä½¿ç”¨ `InterListFunction`ã€‚
                  - å¦‚æœ API å“åº”åŒ…å« `data`, `success` -> **å¿…é¡»**ä½¿ç”¨ `InterDataFunction`ã€‚
                  - æ™®é€šå“åº” -> ä½¿ç”¨ `InterFunction`ã€‚

                ### Step 2: æå– API ä¿¡æ¯
                æå– Method, Path, Summary, Parameters, RequestBody, Responsesã€‚

                ### Step 3: ä»£ç ç”Ÿæˆ
                1. **å‘½å**: ä¼˜å…ˆä½¿ç”¨ Summary ç¿»è¯‘ä¸º PascalCase ä½œä¸ºç±»å‹åï¼Œå°é©¼å³°ä½œä¸ºæ–¹æ³•åã€‚
                2. **ç±»å‹åˆå¹¶**: å°†æ‰€æœ‰æ–°ç”Ÿæˆçš„ Type å®šä¹‰æ”¾åœ¨ä¸€èµ·ã€‚
                3. **å®ç°åˆå¹¶**: å¦‚æœæ¨¡æ¿æœ‰ `Api` å¯¹è±¡ï¼Œç”Ÿæˆä¸€ä¸ª**åˆå¹¶å**çš„å®Œæ•´å¯¹è±¡ã€‚

                ## âš ï¸ ä¸¥æ ¼çº¦æŸ

                - **ç¦æ­¢ Markdown**: ç›´æ¥è¾“å‡ºçº¯ä»£ç ï¼Œä¸è¦åŒ…è£¹åœ¨ ```typescript ä¸­ã€‚
                - **ç¦æ­¢è§£é‡Š**: ä¸¥ç¦è¾“å‡º "Here is the code" ç­‰ä»»ä½•åºŸè¯ã€‚
                - **100% æ¨¡ä»¿**: åŒ…æ‹¬ç¼©è¿›ï¼ˆ2æ ¼ï¼‰ã€å¼•å·ï¼ˆå•å¼•å·ï¼‰ã€åˆ†å·ï¼ˆä¸è¦ï¼‰ã€‚

                ## ğŸ’¡ Few-Shot ç¤ºä¾‹

                ### è¾“å…¥:
                **Template**:
                ```typescript
                import { InterFunction } from '@/utils/interface'
                export type UserGet = InterFunction<{ id: string }, { name: string }>
                export const UserApi = {
                  UserGet: (params) => request.get({ url: '/api/user', params })
                }
                ```
                **API**:
                ```
                Endpoint: POST /api/user/list
                Summary: è·å–ç”¨æˆ·åˆ—è¡¨
                Responses: {"list":[], "total":0}
                ```

                ### è¾“å‡º:
                export type UserListPage = InterListFunction<
                  { keyword?: string },
                  { id: string; name: string }
                >

                export const UserApi = {
                  UserGet: (params) => {
                    return request.get({ url: '/api/user', params })
                  },
                  UserListPage: (data) => {
                    return request.post({ url: '/api/user/list', data })
                  }
                }

                ---
                **ç°åœ¨å¼€å§‹ç”Ÿæˆã€‚åªéœ€è¾“å‡ºä»£ç ã€‚**
            - id: user-prompt
              role: user
              text: |
                è¯·ä¸¥æ ¼éµå¾ªç³»ç»Ÿæç¤ºè¯ä¸­çš„è§„åˆ™ï¼ŒåŸºäºä½ æ‰€åˆ†æçš„ã€ä»£ç æ¨¡æ¿ã€‘é£æ ¼ï¼Œä¸ºã€ç›®æ ‡æ¥å£å®šä¹‰ã€‘ç”Ÿæˆä»¿å†™ä»£ç ã€‚æ³¨æ„ï¼šåªè¾“å‡ºä»£ç ï¼Œä¸¥ç¦å¸¦æœ‰ Markdown ä»£ç å—æ ‡è®°ï¼ˆ```ï¼‰ã€‚

          selected: false
          title: LLM ä»¿å†™å™¨
          type: llm
          variables: []
          vision:
            enabled: false
        height: 89
        id: 'llm-node'
        position:
          x: 380
          y: 282
        positionAbsolute:
          x: 380
          y: 282
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          answer: '{{#llm-node.text#}}'
          desc: 'è¾“å‡ºç”Ÿæˆç»“æœ'
          title: ç›´æ¥å›å¤
          type: answer
          variables: []
        height: 104
        id: 'answer-node'
        position:
          x: 680
          y: 282
        positionAbsolute:
          x: 680
          y: 282
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
